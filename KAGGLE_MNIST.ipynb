{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c756e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- NeuroLoft Aesthetic Config ---\n",
    "plt.style.use('dark_background')\n",
    "sns.set_palette(\"viridis\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"üü¢ System Ready. Compute Node: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a370aa0",
   "metadata": {},
   "source": [
    "## 2. üíæ Data Plane Activation\n",
    "*Ingesting raw pixel data and reshaping for the visual cortex.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d522c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "# Note: On Kaggle, paths will be '/kaggle/input/digit-recognizer/train.csv'\n",
    "try:\n",
    "    train_df = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n",
    "    test_df = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\n",
    "    print(\"‚úÖ Data Loaded Successfully from Kaggle Input\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è Local mode: Generating dummy data for testing structure\")\n",
    "    # Fix: Labels must be 0-9 for MNIST, pixels 0-255\n",
    "    train_df = pd.DataFrame(np.random.randint(0, 255, (100, 785)), columns=['label'] + [f'pixel{i}' for i in range(784)])\n",
    "    train_df['label'] = np.random.randint(0, 10, 100) # Force labels to be 0-9\n",
    "    test_df = pd.DataFrame(np.random.randint(0, 255, (50, 784)), columns=[f'pixel{i}' for i in range(784)])\n",
    "\n",
    "# Preprocessing\n",
    "X = train_df.drop('label', axis=1).values / 255.0\n",
    "y = train_df['label'].values\n",
    "X_test = test_df.values / 255.0\n",
    "\n",
    "# Reshape for CNN (Batch, Channel, Height, Width)\n",
    "X = X.reshape(-1, 1, 28, 28)\n",
    "X_test = X_test.reshape(-1, 1, 28, 28)\n",
    "\n",
    "# Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# To Tensors\n",
    "train_tensor = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "val_tensor = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(train_tensor, batch_size=64, shuffle=True),\n",
    "    'val': DataLoader(val_tensor, batch_size=64, shuffle=False)\n",
    "}\n",
    "\n",
    "print(f\"üìä Training Tensor Shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc0ba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(X_train[i][0], cmap='magma')\n",
    "    plt.title(f\"Label: {y_train[i]}\", color='#40E0D0')\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"üëÅÔ∏è Visual Input Stream\", color='white', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b53b067",
   "metadata": {},
   "source": [
    "## 3. üß† Intelligence Core (CNN)\n",
    "*Constructing the Convolutional Neural Network architecture.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuroCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuroCNN, self).__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = NeuroCNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fabe08",
   "metadata": {},
   "source": [
    "## 4. üîÆ Neural Interface Simulation (Training)\n",
    "*Optimizing synaptic weights.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc6848",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5 # Quick run for demo\n",
    "history = {'loss': [], 'acc': []}\n",
    "\n",
    "print(\"üöÄ Initiating Training Sequence...\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in loaders['train']:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    epoch_acc = 100 * correct / total\n",
    "    history['loss'].append(running_loss / len(loaders['train']))\n",
    "    history['acc'].append(epoch_acc)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {running_loss/len(loaders['train']):.4f} | Acc: {epoch_acc:.2f}%\")\n",
    "\n",
    "print(\"‚úÖ Training Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e23b5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Submission ---\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_preds = model(test_tensor.to(device))\n",
    "    _, predicted_labels = torch.max(test_preds, 1)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'ImageId': range(1, len(predicted_labels) + 1),\n",
    "    'Label': predicted_labels.cpu().numpy()\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"üíæ Submission file 'submission.csv' generated successfully.\")\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
